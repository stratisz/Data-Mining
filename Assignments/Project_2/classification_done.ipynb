{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Εργασία 2 ΤΕΔεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κωνσταντίνος Σκορδούλης 1115201600155\n",
    "\n",
    "Ευστράτιος Ζωγραφάκης 1115201600049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statistics #for standard deviation\n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_name = './train_set_testing.tsv' #HERE\n",
    "train_name = './train_set.tsv'\n",
    "\n",
    "#test_name = './test_set_testing.tsv'#HERE\n",
    "test_name = './test_set.tsv'\n",
    "\n",
    "#y_test_name = './Y_test_testing.tsv' #HERE\n",
    "y_test_name = './Y_test.tsv'\n",
    "\n",
    "\n",
    "Train_df = pd.read_csv(train_name,sep='\\t', usecols=['Id','Title','Content','Category'])\n",
    "#Train_df.index = Train_df['Id']\n",
    "\n",
    "Test_df = pd.read_csv(test_name,sep='\\t', usecols=['Id','Title','Content'])\n",
    "#Test_df.index = Test_df['Id']\n",
    "\n",
    "Y_test =  pd.read_csv(y_test_name,sep='\\t')\n",
    "#Y_test.index = Test_df['Id']\n",
    "\n",
    "#Train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding our labels with <b>LabelEncoder</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "lb.fit(Train_df['Category'])\n",
    "\n",
    "labels_test = lb.transform(Y_test['Category'])\n",
    "labels_train = lb.transform(Train_df['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create <b>bag of Words</b> (μόνο για το Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(max_df=1.0, min_df=1, max_features=1000,\n",
    "stop_words='english')\n",
    "\n",
    "counts_train = bow_vectorizer.fit_transform(Train_df.Content)\n",
    "counts_test = bow_vectorizer.transform(Test_df.Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfrom count to tfidf --> <b>TFidf_Transformer()</b> ---> maybe TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, max_features=1000,\n",
    "stop_words='english')\n",
    "\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(Train_df.Content)\n",
    "tfidf_test = tfidf_vectorizer.transform(Test_df.Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict1(X_train,Y_train,X_test,k,knn_fold):\n",
    "\n",
    "    \n",
    "    dist = [] # a list of list (dist,index_train)\n",
    "    neighbors = []\n",
    "    \n",
    "    \n",
    "    for i in range(X_train.shape[0]): #for each train data point\n",
    "        \n",
    "        x1 = X_test - X_train[i,:]        \n",
    "        x2 = np.square([x1])\n",
    "        x3 = np.sqrt(np.sum(x2))\n",
    "        dist.append([x3,i])\n",
    "            \n",
    "    #sort distances(ascending)\n",
    "    dist = sorted(dist)\n",
    "    \n",
    "    #Find k-nearest neighbors\n",
    "    for i in range(k):\n",
    "        index = dist[i][1]\n",
    "        neighbors.append(Y_train[index])\n",
    "    \n",
    "    #Now for the Majority Vote(use Countw)\n",
    "    c1 = Counter(neighbors)    \n",
    "    \n",
    "    if knn_fold == False:\n",
    "        result = c1.most_common(1) # returns [(word,frequency)]\n",
    "        return result[0][0] #we only want the word  \n",
    "    else:\n",
    "        result = c1.most_common(k)\n",
    "        return result # we want this list of tupples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train,Y_train,X_test,k,knn_fold):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    result1 = [] #in case of knn_fold = true\n",
    "    for i in range(X_test.shape[0]):\n",
    " \n",
    "        x = knn_predict1(X_train,Y_train,X_test[i,:],k,knn_fold)\n",
    "    \n",
    "        if( knn_fold == True):\n",
    "            result1.append(x[0][0])            \n",
    "        result.append(x)\n",
    "    \n",
    "    if( knn_fold == True):\n",
    "        return [result1,result] #result1 (list) contains the predicted labels\n",
    "        #while result (list of lists of tupples) which is usefull for computing the probabilities (roc_auc_score)\n",
    "    \n",
    "    \n",
    "    #else just return the labels\n",
    "    return result #contains label for each X_test  (or a list of lists, containing tupples (word,frequency) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose <b>k</b> as the <b>sqrt( len( X_train ) )</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(np.sqrt(len(Train_df)))\n",
    "\n",
    "if( k % 2 == 0): #we want odd number\n",
    "    k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_labels = ['precision_macro','recall_macro','f1_macro','balanced_accuracy','roc_auc_ovo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our very own cross_val_score(), using the functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_10fold(X_train,Y_train,k,label_encoder):\n",
    "#def knn_10fold(X_train,Y_train,k):\n",
    "\n",
    "    label_order = ['business','entertainment','politics','sport','tech']\n",
    "\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    accuracy_list = []\n",
    "    roc_auc_list = []        \n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        X_train1,X_test1,Y_train1,Y_test1 = train_test_split(X_train,Y_train, test_size=0.1, stratify=Y_train)\n",
    "        \n",
    "        Y_train1 = Y_train1.reset_index(drop=True) #reset indices    \n",
    "        Y_pred, list_coll = knn(X_train1,Y_train1,X_test1,k,True)\n",
    "        \n",
    "        \n",
    "        #Now get the probability matrix for\n",
    "        Y_pred_proba = Compute_proba(list_coll,label_order,k)\n",
    "        \n",
    "        \n",
    "        Y_pred = label_encoder.transform(Y_pred) #encode the predicted labels\n",
    "        Y_test2 = label_encoder.transform(Y_test1) #encode the true test label\n",
    "        \n",
    "        precision_macro = precision_score(Y_test2, Y_pred, average='macro')\n",
    "        recall_macro = recall_score(Y_test2,Y_pred, average='macro')\n",
    "        f1_macro = f1_score(Y_test2, Y_pred, average='macro')\n",
    "        accuracy_b = balanced_accuracy_score(Y_test2, Y_pred)\n",
    "        \n",
    "        \n",
    "        #roc_auc = roc_auc_score(Y_test2, Y_pred, average='macro', multi_class='ovo')\n",
    "        roc_auc = roc_auc_score(Y_test2,Y_pred_proba, average='macro', multi_class='ovo')\n",
    "        \n",
    "        precision_list.append(precision_macro)\n",
    "        recall_list.append(recall_macro)\n",
    "        f1_list.append(f1_macro)\n",
    "        accuracy_list.append(accuracy_b)\n",
    "        roc_auc_list.append(roc_auc)\n",
    "\n",
    "    \n",
    "    return [precision_list,recall_list,f1_list,accuracy_list,roc_auc_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compute_proba(list1,label_order,k):\n",
    "    \n",
    "   #list1 is a list of list of tupples (word,frequency_int)\n",
    "    \n",
    "    final_list = [] #our final array for the roc_auc_score\n",
    "\n",
    "    for l in list1: #for each test point\n",
    "    \n",
    "        list2 = [] #probabilities of this test point\n",
    "    \n",
    "        dict1={} #contains the probabilities of each label\n",
    "        for x in l:\n",
    "            dict1[x[0]] = x[1] / k\n",
    "        #end of loop\n",
    "        \n",
    "        for x in label_order: # ['business','entertainment','politics','sport','tech']\n",
    "            \n",
    "            if x not in dict1.keys():\n",
    "                list2.append(0)\n",
    "            else:\n",
    "                list2.append(dict1[x])\n",
    "                \n",
    "        #end of loop\n",
    "        \n",
    "        final_list.append(list2)\n",
    "\n",
    "    return np.array(final_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kfold_scores(scores):\n",
    "    #scores is a list of scores\n",
    "    \n",
    "    print(\"Precision_macro is (mean : %f) and (standard deviation: %f)\" % ( np.mean(scores[0]), stdev(scores[0]) ) )\n",
    "    print(\"Recall_macro is (mean : %f) and (standard deviation: %f)\" % ( np.mean(scores[1]), stdev(scores[1]) ) )\n",
    "    print(\"f1_macro is (mean : %f) and (standard deviation: %f)\" % ( np.mean(scores[2]), stdev(scores[2]) ) )\n",
    "    \n",
    "    print(\"balanced_accuracy is (mean : %f) and (standard deviation: %f)\" % ( np.mean(scores[3]), stdev(scores[3]) ) )\n",
    "    print(\"Roc_auc_ovo is (mean : %f) and (standard deviation: %f)\" % ( np.mean(scores[4]), stdev(scores[4]) ) )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn count prediction and model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pred_knn = knn(counts_train.toarray(),Train_df['Category'],counts_test.toarray(),k,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5528089887640449"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_pred_knn1 = lb.transform(count_pred_knn)\n",
    "accuracy_score(labels_test, count_pred_knn1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the 10-fold cross_val_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_macro is (mean : 0.764687) and (standard deviation: 0.024675)\n",
      "Recall_macro is (mean : 0.559045) and (standard deviation: 0.025571)\n",
      "f1_macro is (mean : 0.564736) and (standard deviation: 0.030575)\n",
      "balanced_accuracy is (mean : 0.559045) and (standard deviation: 0.025571)\n",
      "Roc_auc_ovo is (mean : 0.951276) and (standard deviation: 0.011237)\n"
     ]
    }
   ],
   "source": [
    "score_list = knn_10fold(counts_train.toarray(),Train_df['Category'],k,lb)\n",
    "print_kfold_scores(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pred_knn = knn(tfidf_train.toarray(),Train_df['Category'],tfidf_test.toarray(),k,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9370786516853933"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pred_knn1 = lb.transform(tfidf_pred_knn)\n",
    "accuracy_score(labels_test, tfidf_pred_knn1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the 10-fold cross_val_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_macro is (mean : 0.937173) and (standard deviation: 0.026319)\n",
      "Recall_macro is (mean : 0.934403) and (standard deviation: 0.026672)\n",
      "f1_macro is (mean : 0.934897) and (standard deviation: 0.026679)\n",
      "balanced_accuracy is (mean : 0.934403) and (standard deviation: 0.026672)\n",
      "Roc_auc_ovo is (mean : 0.996058) and (standard deviation: 0.002440)\n"
     ]
    }
   ],
   "source": [
    "score_list = knn_10fold(tfidf_train.toarray(),Train_df['Category'],k,lb)\n",
    "print_kfold_scores(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όπως με κάθε classifier, θα χρειαστούμε να:\n",
    "\n",
    "1) να βρούμε τις κατάλληλες hyperparameters (ανάλογα με το training dataset-> counts or tfidf) με τη βοήθεια του GridSearchCV\n",
    "\n",
    "2) Να κάνουμε train/fit to μοντέλο μας (με χρήση του training_data)\n",
    "\n",
    "3) Να κάνουμε predict (με χρήση του testing_data)\n",
    "\n",
    "4) Scoring\n",
    "\n",
    "    a) Accuracy του predict\n",
    "   \n",
    "    b) 10-fold crοss validation -> cross_val_score() --> όλα όσα ζητάει (precision κλπ). \n",
    "    Θέλουμε μέσο όρο και τυπική απόκλιση για κάθε score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphas = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "#alphas = [0.1,0.01,0.001,0.0001,0.0001,0.000001] #0.0010\n",
    "#alphas = [0.0003, 0.0008] #0.0008\n",
    "#alphas = [0.0009, 0.00095] #0.0009\n",
    "#alphas = [0.00092,0.00094] #0.00092\n",
    "#alphas = [0.00091,0.00092] #0.00091\n",
    "#alphas = [0.000905, 0.00091] #0.00905\n",
    "#alphas = [0.000902,0.000904] #0.000902\n",
    "\n",
    "alphas = [0.000902] # ===> OK\n",
    "\n",
    "#pgrid = {'alpha': alphas, 'fit_prior': [True,False],'class_prior': [None, [0.1,0.9], [0.2,0.8]] }\n",
    "pgrid = {'alpha': alphas, 'fit_prior': [True,False],'class_prior': [None] }\n",
    "#Number of priors must match number of classes -> example: [0.1,0.1,0.1,0.1,0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.000902, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mnb = MultinomialNB()\n",
    "\n",
    "grid = GridSearchCV(estimator=MultinomialNB(), param_grid=pgrid, scoring=scoring_labels, refit='balanced_accuracy', cv=10)\n",
    "grid.fit(counts_train,labels_train)\n",
    "\n",
    "mnb = grid.best_estimator_ #returns the optimized model (in regards to the parameters)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.000902, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(counts_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.predict() and <b>accuracy of our prediction</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_counts_pred = mnb.predict(counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946067415730337"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test, mnb_counts_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_scores -> cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores = cross_val_score(mnb, counts_train, labels_train, cv=10, scoring='precision_macro')\n",
    "recall_scores = cross_val_score(mnb, counts_train, labels_train, cv=10, scoring='recall_macro')\n",
    "f1_scores = cross_val_score(mnb, counts_train, labels_train, cv=10, scoring='f1_macro')\n",
    "kfold_accuracy_scores = cross_val_score(mnb, counts_train, labels_train, cv=10, scoring='balanced_accuracy')\n",
    "ROC_scores = cross_val_score(mnb, counts_train, labels_train, cv=10, scoring='roc_auc_ovo')\n",
    "\n",
    "score_list = [precision_scores,recall_scores,f1_scores,kfold_accuracy_scores,ROC_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_macro is (mean : 0.969957) and (standard deviation: 0.010605)\n",
      "Recall_macro is (mean : 0.968899) and (standard deviation: 0.011760)\n",
      "f1_macro is (mean : 0.968772) and (standard deviation: 0.011755)\n",
      "balanced_accuracy is (mean : 0.968899) and (standard deviation: 0.011760)\n",
      "Roc_auc_ovo is (mean : 0.996706) and (standard deviation: 0.003415)\n"
     ]
    }
   ],
   "source": [
    "print_kfold_scores(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphas = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "#alphas = [0.1,0.01,0.001,0.0001,0.0001,0.000001] # 0.001\n",
    "#alphas = [0.0005,0.0008] #0.0008\n",
    "#alphas = [0.0008,0.00085] #0.0008\n",
    "\n",
    "alphas = [0.0008] # ===> OK\n",
    "\n",
    "#pgrid = {'alpha': alphas, 'fit_prior': [True,False],'class_prior': [None, [0.1,0.9], [0.2,0.8]] }\n",
    "pgrid = {'alpha': alphas, 'fit_prior': [True,False],'class_prior': [None] }\n",
    "#Number of priors must match number of classes -> example: [0.1,0.1,0.1,0.1,0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0008, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mnb = MultinomialNB()\n",
    "\n",
    "grid = GridSearchCV(estimator=MultinomialNB(), param_grid=pgrid, scoring=scoring_labels, refit='balanced_accuracy', cv=10)\n",
    "grid.fit(tfidf_train,labels_train)\n",
    "\n",
    "mnb = grid.best_estimator_ #returns the optimized model (in regards to the parameters)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.0008, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(tfidf_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.predict() and <b>accuracy of our prediction</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_tfidf_pred = mnb.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9483146067415731"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test, mnb_tfidf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_scores -> cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores = cross_val_score(mnb, tfidf_train, labels_train, cv=10, scoring='precision_macro')\n",
    "recall_scores = cross_val_score(mnb, tfidf_train, labels_train, cv=10, scoring='recall_macro')\n",
    "f1_scores = cross_val_score(mnb, tfidf_train, labels_train, cv=10, scoring='f1_macro')\n",
    "kfold_accuracy_scores = cross_val_score(mnb, tfidf_train, labels_train, cv=10, scoring='balanced_accuracy')\n",
    "ROC_scores = cross_val_score(mnb, tfidf_train, labels_train, cv=10, scoring='roc_auc_ovo')\n",
    "\n",
    "score_list = [precision_scores,recall_scores,f1_scores,kfold_accuracy_scores,ROC_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_macro is (mean : 0.971517) and (standard deviation: 0.009526)\n",
      "Recall_macro is (mean : 0.970354) and (standard deviation: 0.010638)\n",
      "f1_macro is (mean : 0.970426) and (standard deviation: 0.010496)\n",
      "balanced_accuracy is (mean : 0.970354) and (standard deviation: 0.010638)\n",
      "Roc_auc_ovo is (mean : 0.998438) and (standard deviation: 0.001265)\n"
     ]
    }
   ],
   "source": [
    "print_kfold_scores(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Gini to minimize miss-classification\n",
    "\n",
    "#max_depth = [10,20,30,40,50,60,70,80,90,100]\n",
    "#max_depth = [10,50,100]\n",
    "#max_depth=[5,10] # 10\n",
    "#max_depth=[15,30] # 30\n",
    "#max_depth=[35,60] #35\n",
    "#max_depth=[32,34] #34\n",
    "\n",
    "max_depth=[34] # ====> OK\n",
    "\n",
    "\n",
    "\n",
    "#max_features = [1,2,3,4,5,6,7,8,9,10]\n",
    "#max_features=[2,5,10] #10\n",
    "#max_features=[15,30] # 15\n",
    "#max_features=[11,12,13,14,15] # 11\n",
    "\n",
    "max_features = [11] # =====> OK\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#min_samples_leaf = [1,2,3,4,5,6,7,8,9,10]\n",
    "#min_samples_leaf=[2,5,10] #5\n",
    "#min_samples_leaf=[3,4,5] # 3\n",
    "\n",
    "min_samples_leaf=[3] # ==> OK\n",
    "\n",
    "\n",
    "#min_samples_split = [2,4,6,8,10,12,14,16]\n",
    "#min_samples_split=[2,5,10] #5\n",
    "#min_samples_split=[3,4,5] # 5\n",
    "#min_samples_split=[5,6,7,8,9] # 9\n",
    "\n",
    "min_samples_split=[9] #===> OK\n",
    "\n",
    "\n",
    "#n_estimators = [10,50,100,150,200,250]\n",
    "#n_estimators = [5,10] # 10\n",
    "#n_estimators =[15,30] # 30\n",
    "#n_estimators =[35,60] #60\n",
    "#n_estimators = [100,200] #200\n",
    "#n_estimators = [400,800] #800\n",
    "#n_estimators = [1000,2500] #1000\n",
    "#n_estimators = [900,1500] #1500\n",
    "#n_estimators = [1600,2000] #1600\n",
    "#n_estimators = [1530,1570] # 1570\n",
    "#n_estimators = [1580,1590] #1590\n",
    "#n_estimators =[1593,1597] #1593\n",
    "#n_estimators = [1591,1592] #1591\n",
    "\n",
    "n_estimators = [1591] # ====> OK\n",
    "\n",
    "\n",
    "class_weight = ['balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid = {'bootstrap':[True], 'max_depth':max_depth, 'max_features':max_features, 'min_samples_leaf':min_samples_leaf, \n",
    "         'min_samples_split': min_samples_split, 'n_estimators':n_estimators,\n",
    "        'class_weight':class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_depth': 34,\n",
       " 'max_features': 11,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 9,\n",
       " 'n_estimators': 1591}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=RandomForestClassifier(), param_grid=pgrid, scoring=scoring_labels, refit='balanced_accuracy', cv=10)\n",
    "grid.fit(counts_train,labels_train)\n",
    "\n",
    "rfc = grid.best_estimator_ #returns the optimized model (in regards to the parameters)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=34, max_features=11,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=9,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1591,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(counts_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.predict() and <b>accuracy of our prediction</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_counts_pred = rfc.predict(counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952808988764045"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test, rfc_counts_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_scores -> cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores = cross_val_score(rfc, counts_train, labels_train, cv=10, scoring='precision_macro')\n",
    "recall_scores = cross_val_score(rfc, counts_train, labels_train, cv=10, scoring='recall_macro')\n",
    "f1_scores = cross_val_score(rfc, counts_train, labels_train, cv=10, scoring='f1_macro')\n",
    "kfold_accuracy_scores = cross_val_score(rfc, counts_train, labels_train, cv=10, scoring='balanced_accuracy')\n",
    "ROC_scores = cross_val_score(rfc, counts_train, labels_train, cv=10, scoring='roc_auc_ovo')\n",
    "\n",
    "score_list = [precision_scores,recall_scores,f1_scores,kfold_accuracy_scores,ROC_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_macro is (mean : 0.964296) and (standard deviation: 0.013088)\n",
      "Recall_macro is (mean : 0.962906) and (standard deviation: 0.012719)\n",
      "f1_macro is (mean : 0.966497) and (standard deviation: 0.012189)\n",
      "balanced_accuracy is (mean : 0.965819) and (standard deviation: 0.013712)\n",
      "Roc_auc_ovo is (mean : 0.997928) and (standard deviation: 0.001271)\n"
     ]
    }
   ],
   "source": [
    "print_kfold_scores(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Gini to minimize miss-classification\n",
    "\n",
    "#max_depth = [10,20,30,40,50,60,70,80,90,100]\n",
    "#max_depth = [10,50,100]\n",
    "#max_depth=[5,10]\n",
    "#max_depth=[30,34] \n",
    "\n",
    "\n",
    "max_depth=[34] # ====> OK\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#max_features = [1,2,3,4,5,6,7,8,9,10]\n",
    "#max_features=[2,5,10]\n",
    "#max_features = [9,11] \n",
    "\n",
    "max_features = [11] # =====> OK\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#min_samples_leaf = [1,2,3,4,5,6,7,8,9,10]\n",
    "#min_samples_leaf=[2,5,10]\n",
    "#min_samples_leaf=[3,5] \n",
    "\n",
    "min_samples_leaf=[3] # ==> OK\n",
    "\n",
    "\n",
    "\n",
    "#min_samples_split = [2,4,6,8,10,12,14,16]\n",
    "#min_samples_split=[2,5,10]\n",
    "#min_samples_split=[9,11] \n",
    "\n",
    "min_samples_split=[9] #===> OK\n",
    "\n",
    "\n",
    "\n",
    "#n_estimators = [10,50,100,150,200,250]\n",
    "#n_estimators = [5,10]\n",
    "#n_estimators = [1591,1600] \n",
    "\n",
    "n_estimators = [1591] # ====> OK\n",
    "\n",
    "\n",
    "\n",
    "class_weight = ['balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid = {'bootstrap':[True], 'max_depth':max_depth, 'max_features':max_features, 'min_samples_leaf':min_samples_leaf, \n",
    "         'min_samples_split': min_samples_split, 'n_estimators':n_estimators,\n",
    "        'class_weight':class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_depth': 34,\n",
       " 'max_features': 11,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 9,\n",
       " 'n_estimators': 1591}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=RandomForestClassifier(), param_grid=pgrid, scoring=scoring_labels, refit='balanced_accuracy', cv=10)\n",
    "grid.fit(tfidf_train,labels_train)\n",
    "\n",
    "rfc = grid.best_estimator_ #returns the optimized model (in regards to the parameters)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=34, max_features=11,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=9,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1591,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(tfidf_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.predict() and <b>accuracy of our prediction</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tfidf_pred = rfc.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952808988764045"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test, rfc_tfidf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_scores -> cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores = cross_val_score(rfc, tfidf_train, labels_train, cv=10, scoring='precision_macro')\n",
    "recall_scores = cross_val_score(rfc, tfidf_train, labels_train, cv=10, scoring='recall_macro')\n",
    "f1_scores = cross_val_score(rfc, tfidf_train, labels_train, cv=10, scoring='f1_macro')\n",
    "kfold_accuracy_scores = cross_val_score(rfc, tfidf_train, labels_train, cv=10, scoring='balanced_accuracy')\n",
    "ROC_scores = cross_val_score(rfc, tfidf_train, labels_train, cv=10, scoring='roc_auc_ovo')\n",
    "\n",
    "score_list = [precision_scores,recall_scores,f1_scores,kfold_accuracy_scores,ROC_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_macro is (mean : 0.963017) and (standard deviation: 0.011765)\n",
      "Recall_macro is (mean : 0.959470) and (standard deviation: 0.012975)\n",
      "f1_macro is (mean : 0.958873) and (standard deviation: 0.013810)\n",
      "balanced_accuracy is (mean : 0.957692) and (standard deviation: 0.013760)\n",
      "Roc_auc_ovo is (mean : 0.998033) and (standard deviation: 0.001108)\n"
     ]
    }
   ],
   "source": [
    "print_kfold_scores(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C = [1.0,5.0,10.0]\n",
    "#C=[1.0,5.0] #5.0\n",
    "#C=[10.0,100.0] #10.0\n",
    "#C=[10.0,50.0] #10.0\n",
    "#C= [10.0,12.0] # 10.0\n",
    "#C= [7.0,10.0] #7.0\n",
    "#C = [6.0,7.0] #7.0\n",
    "#C = [7.5,9.0] #7.5\n",
    "#C = [7.0,7.1,7.2,7.3,7.4,7.5] #7.0\n",
    "\n",
    "C = [7.0] # ==> OK\n",
    "\n",
    "\n",
    "\n",
    "#kernel = ['rbf','linear'] #rbf\n",
    "kernel = ['rbf'] # ===> OK\n",
    "\n",
    "#gamma = ['scale','auto'] #auto\n",
    "gamma = ['auto'] # ===> OK\n",
    "\n",
    "\n",
    "#######################\n",
    "probability = [True]\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "decision_function_shape=['ovo'] #or 'ovr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid = {'kernel':kernel, 'C':C, 'gamma':gamma, 'decision_function_shape':decision_function_shape,\n",
    "         'class_weight':class_weight, 'probability':probability}\n",
    "\n",
    "#pgrid = {'kernel':kernel, 'C':C, 'gamma':gamma, 'probability':probability}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 7.0,\n",
       " 'class_weight': 'balanced',\n",
       " 'decision_function_shape': 'ovo',\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'probability': True}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid = GridSearchCV(estimator=SVC(), param_grid=pgrid, scoring=scoring_labels, refit='balanced_accuracy', cv=10)\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=pgrid, scoring=scoring_labels, refit='balanced_accuracy')\n",
    "\n",
    "grid.fit(counts_train,labels_train)\n",
    "\n",
    "svc = grid.best_estimator_ #returns the optimized model (in regards to the parameters)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=7.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(counts_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.predict() and <b>accuracy of our prediction</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_counts_pred = svc.predict(counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9438202247191011"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test, svc_counts_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_scores -> cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores = cross_val_score(svc, counts_train, labels_train, cv=10, scoring='precision_macro')\n",
    "recall_scores = cross_val_score(svc, counts_train, labels_train, cv=10, scoring='recall_macro')\n",
    "f1_scores = cross_val_score(svc, counts_train, labels_train, cv=10, scoring='f1_macro')\n",
    "kfold_accuracy_scores = cross_val_score(svc, counts_train, labels_train, cv=10, scoring='balanced_accuracy')\n",
    "ROC_scores = cross_val_score(svc, counts_train, labels_train, cv=10, scoring='roc_auc_ovo')\n",
    "\n",
    "score_list = [precision_scores,recall_scores,f1_scores,kfold_accuracy_scores,ROC_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_macro is (mean : 0.962982) and (standard deviation: 0.010535)\n",
      "Recall_macro is (mean : 0.962742) and (standard deviation: 0.010950)\n",
      "f1_macro is (mean : 0.962460) and (standard deviation: 0.010719)\n",
      "balanced_accuracy is (mean : 0.962742) and (standard deviation: 0.010950)\n",
      "Roc_auc_ovo is (mean : 0.997473) and (standard deviation: 0.001481)\n"
     ]
    }
   ],
   "source": [
    "print_kfold_scores(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change from precision_macro to precision_micro, because there was slight class imbalance (even with stratified train_test_split). ===> We receive this error:\n",
    "\n",
    "UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_labels1 = ['precision_micro','recall_macro','f1_macro','balanced_accuracy','roc_auc_ovo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C = [1.0,5.0,10.0] # ==> 1.0\n",
    "#C=[0.1,0.9] #0.9\n",
    "#C=[0.9,1.0] #0.9\n",
    "\n",
    "C = [0.9] # ===> OK\n",
    "\n",
    "\n",
    "#kernel = ['rbf','linear']\n",
    "kernel = ['rbf'] # ===> OK\n",
    "\n",
    "#gamma = ['scale','auto']\n",
    "gamma = ['scale'] # ===> OK\n",
    "\n",
    "\n",
    "#######################\n",
    "probability = [True]\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "decision_function_shape=['ovo'] #or 'ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid = {'kernel':kernel, 'C':C, 'gamma':gamma, 'decision_function_shape':decision_function_shape,\n",
    "         'class_weight':class_weight, 'probability':probability}\n",
    "\n",
    "#pgrid = {'kernel':kernel, 'C':C, 'gamma':gamma, 'probability':probability}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.9,\n",
       " 'class_weight': 'balanced',\n",
       " 'decision_function_shape': 'ovo',\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'probability': True}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=SVC(), param_grid=pgrid, scoring=scoring_labels1, refit='balanced_accuracy', cv=10)\n",
    "#grid = GridSearchCV(estimator=SVC(), param_grid=pgrid, scoring=scoring_labels, refit='balanced_accuracy')\n",
    "\n",
    "grid.fit(tfidf_train,labels_train)\n",
    "\n",
    "svc = grid.best_estimator_ #returns the optimized model (in regards to the parameters)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.9, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(tfidf_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.predict() and <b>accuracy of our prediction</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tfidf_pred = svc.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952808988764045"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test, svc_tfidf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_scores -> cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision_scores = cross_val_score(svc, tfidf_train, labels_train, cv=10, scoring='precision_macro')\n",
    "precision_scores = cross_val_score(svc, tfidf_train, labels_train, cv=10, scoring='precision_micro')\n",
    "\n",
    "\n",
    "recall_scores = cross_val_score(svc, tfidf_train, labels_train, cv=10, scoring='recall_macro')\n",
    "f1_scores = cross_val_score(svc, tfidf_train, labels_train, cv=10, scoring='f1_macro')\n",
    "kfold_accuracy_scores = cross_val_score(svc, tfidf_train, labels_train, cv=10, scoring='balanced_accuracy')\n",
    "ROC_scores = cross_val_score(svc, tfidf_train, labels_train, cv=10, scoring='roc_auc_ovo')\n",
    "\n",
    "score_list = [precision_scores,recall_scores,f1_scores,kfold_accuracy_scores,ROC_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_kfold_scores(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_micro is (mean : 0.976404) and (standard deviation: 0.010855)\n",
      "Recall_macro is (mean : 0.976140) and (standard deviation: 0.010580)\n",
      "f1_macro is (mean : 0.976168) and (standard deviation: 0.010681)\n",
      "balanced_accuracy is (mean : 0.976140) and (standard deviation: 0.010580)\n",
      "Roc_auc_ovo is (mean : 0.998764) and (standard deviation: 0.000982)\n"
     ]
    }
   ],
   "source": [
    "    print(\"Precision_micro is (mean : %f) and (standard deviation: %f)\" % ( np.mean(score_list[0]), stdev(score_list[0]) ) )\n",
    "    print(\"Recall_macro is (mean : %f) and (standard deviation: %f)\" % ( np.mean(score_list[1]), stdev(score_list[1]) ) )\n",
    "    print(\"f1_macro is (mean : %f) and (standard deviation: %f)\" % ( np.mean(score_list[2]), stdev(score_list[2]) ) )\n",
    "    \n",
    "    print(\"balanced_accuracy is (mean : %f) and (standard deviation: %f)\" % ( np.mean(score_list[3]), stdev(score_list[3]) ) )\n",
    "    print(\"Roc_auc_ovo is (mean : %f) and (standard deviation: %f)\" % ( np.mean(score_list[4]), stdev(score_list[4]) ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
